{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjilpGJqGSliFPRAP3RftB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devesssi/dl-playground/blob/main/Copy_of_d2_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DAY 02**\n",
        "\n",
        "\n",
        "Matrix multiplication (is all you need)\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the torch.matmul() method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "Matrix multiplication (is all you need)\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the torch.matmul() method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "The inner dimensions must match:\n",
        "(3, 2) @ (3, 2) won't work\n",
        "(2, 3) @ (3, 2) will work\n",
        "(3, 2) @ (2, 3) will work\n",
        "The resulting matrix has the shape of the outer dimensions:\n",
        "(2, 3) @ (3, 2) -> (2, 2)\n",
        "(3, 2) @ (2, 3) -> (3, 3)\n",
        "Note: \"@\" in Python is the symbol for matrix multiplication.\n",
        "\n",
        "Resource: You can see all of the rules for matrix multiplication using torch.matmul() in the [PyTorch documentation.\n",
        "](https://docs.pytorch.org/docs/stable/generated/torch.matmul.html)\n",
        "\n",
        "# Let's create a tensor and perform **element-wise multiplication** and **matrix multiplication** on it.\n",
        "\n"
      ],
      "metadata": {
        "id": "9AamYB-_pI31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "5VcWZiEgpRPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7gs7AQdpM_E",
        "outputId": "e4795659-9f3b-430e-cfc3-d1587e90a36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aepa8aYbkZAR",
        "outputId": "be5c6a25-c04d-48ee-de2b-cf722d44f4b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between element-wise multiplication and matrix multiplication is the addition of values.\n",
        "\n",
        "For our tensor variable\n",
        "\n",
        "Operation\tCalculation\tCode\n",
        "Element-wise multiplication\t[1x1, 2x2, 3x3] = [1, 4, 9]\ttensor * tensor\n",
        "Matrix multiplication\t[1x1 + 2x2 + 3x3] = [14]\ttensor.matmul(tensor)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TveDbO4lrNYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise matrix multiplication\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbeJWOIOqgpC",
        "outputId": "6a1c9aff-a6c1-4308-8d12-bddda1eacd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(tensor , tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCndRlyNqgsL",
        "outputId": "2b4e1a27-f606-4b7f-e772-9a9b243f15a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCjtmgCQqgvJ",
        "outputId": "39c73887-3073-42b0-b42c-c07c322f1179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You can do matrix multiplication by hand but it's not recommended.\n",
        "\n",
        "The in-built torch.matmul() method is faster."
      ],
      "metadata": {
        "id": "DBg8jSdEsjOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#  \" %%time \"this is a magic command use to get the execution time of a single cell\n",
        "# Matrix multiplication by hand\n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru1Xe3qCqgyT",
        "outputId": "2d34fbd3-b1aa-45fe-b4ed-ce03da297e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.41 ms, sys: 0 ns, total: 1.41 ms\n",
            "Wall time: 1.34 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor ,tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zuqt1R3Fqg0S",
        "outputId": "ce69045b-a03e-45fe-ae8c-c6d904293209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 146 µs, sys: 0 ns, total: 146 µs\n",
            "Wall time: 152 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One of the most common errors in deep learning (shape errors)**\n",
        "\n",
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches\n",
        "\n"
      ],
      "metadata": {
        "id": "b2R5a7xJtzo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "7BYT5mI0upKi",
        "outputId": "a6a74997-5609-4ef6-9ff4-df565c0feadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-2761025649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                          [9, 12]], dtype=torch.float32)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2,6],\n",
        "                         [3, 4,7],\n",
        "                         ], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# torch.matmul(tensor_A, tensor_B) # (this will error)\n",
        "# tensor_A.shape , tensor_B.shape\n",
        "tensor_A@tensor_B\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiNf1azftyZA",
        "outputId": "a33e0279-5fa1-41d8-a6a6-b48926bc7766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.31 ms, sys: 0 ns, total: 1.31 ms\n",
            "Wall time: 1.18 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 77., 104.],\n",
              "        [116., 158.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tensor_A@tensor_B\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeYPiFBItybd",
        "outputId": "b042e588-b0fd-445a-a4c2-0d6b96acf679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 723 µs, sys: 0 ns, total: 723 µs\n",
            "Wall time: 637 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 77., 104.],\n",
              "        [116., 158.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can make matrix multiplication work between tensor_A and tensor_B by making their inner dimensions match.\n",
        "\n",
        "One of the ways to do this is with a transpose (switch the dimensions of a given tensor).\n",
        "\n",
        "You can perform transposes in PyTorch using either:\n",
        "\n",
        "torch.transpose(input, dim0, dim1) - where input is the desired tensor to transpose and dim0 and dim1 are the dimensions to be swapped.\n",
        "tensor.T - where tensor is the desired tensor to transpose."
      ],
      "metadata": {
        "id": "X9iJuAuVxDlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View tensor_A and tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH4fkXE9tyjM",
        "outputId": "40e58b5b-0be8-4831-cfc0-23d98e6e6e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 6.],\n",
            "        [3., 4., 7.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwTFW6Pityl2",
        "outputId": "dc478b2c-8bac-4156-c07f-b167133e1a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 6.],\n",
            "        [3., 4., 7.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "look when the dimension like 3x2 ,3x2 you can make the transpose of second one i.e the 3x2 --> 2x3 and hence the tensors can get multiplt acc to the rule: 3x2 , 2x3 inner no matches and the result will be of tensor 3x3\n",
        "\n",
        "\n",
        "\n",
        "# Without the transpose, the rules of matrix multiplication aren't fulfilled and we get an error like above.\n",
        "\n",
        "\n",
        "**Note: A matrix multiplication like this is also referred to as the dot product of two matrices.**"
      ],
      "metadata": {
        "id": "cd9efCM5xqgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "## NOTE MATRIX MUL IS ONE OF THE MOST COMMON OPERATION IN NN AND AS WE EXPLORE DEEP LEARNING```\n",
        "\n"
      ],
      "metadata": {
        "id": "pUvCLRHO1voV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\n",
        "Finding the min, max, mean, sum, etc (aggregation)**"
      ],
      "metadata": {
        "id": "aXCHgUTF2Prh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tor1 = torch.arange(1, 200 , 20)\n",
        "tor1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-IAznM7tyrB",
        "outputId": "d6480dc3-1b0f-421a-d63e-2907e2852dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding the min of the above tensors \"min() is the function\"\n",
        "tor1.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq-glyc7tyuE",
        "outputId": "fbb6715e-e807-4313-804b-7d3408f225d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tor1.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBedQKystyzG",
        "outputId": "8d37f27f-1fb4-449f-e6f3-1cf0be074870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(181)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you must specify the type of the output mean beforhand\n",
        "tor1.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Q1a0rBnlty2L",
        "outputId": "b3b10fa2-98ad-498c-e2ab-3de337a2e567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40-1035056539.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tor1.type(torch.float32).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e6QDJRVty5K",
        "outputId": "3442d9b4-41f3-4419-9605-18c68593c9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(91.)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tor1.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tWfhiRR3Z8J",
        "outputId": "c7eb010b-e9ef-42dd-88b8-6330b0b3b20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(910)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdWMmkO3jWe",
        "outputId": "8c80e4f5-21bd-4865-9086-8208386f1272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPJwAZlD3aS3",
        "outputId": "47ff429a-32e7-4392-e5d0-21af4c0a4051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional min/max\n",
        "You can also find the index of a tensor where the max or minimum occurs with **torch.argmax()** and **torch.argmin() **respectively.\n",
        "\n",
        "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the softmax activation function).\n"
      ],
      "metadata": {
        "id": "cRN8Ia2_33ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X3YEsLZ3aXX",
        "outputId": "e3d4347f-dd5d-412b-bd6a-35d7650b57e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2Scz1WT3a0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change tensor datatype\n",
        "As mentioned, a common issue with deep learning operations is having your tensors in different datatypes.\n",
        "\n",
        "If one tensor is in torch.float64 and another is in torch.float32, you might run into some errors.\n",
        "\n",
        "But there's a fix.\n",
        "\n",
        "You can change the datatypes of tensors using torch.Tensor.type(dtype=None) where the dtype parameter is the datatype you'd like to use.\n",
        "\n",
        "First we'll create a tensor and check its datatype (the default is torch.float32).\n",
        "\n"
      ],
      "metadata": {
        "id": "dmj5PXNr4UKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw3bKGKf3a3c",
        "outputId": "948ca4b3-f263-4b49-8601-de7948e0ee65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuJIYZJp6HKI",
        "outputId": "2bac233f-6821-4f2a-bb16-6b9afde22df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create another tensor the same as before but change its datatype to"
      ],
      "metadata": {
        "id": "1Mi1KyuV4t2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjR74ZDg3a6P",
        "outputId": "19af69f3-43f0-4386-f08f-2eeeb89d23c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can do something similar to make a torch.int8 tensor.\n"
      ],
      "metadata": {
        "id": "E_u_ISjn6Ptn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddQ2ALCe3a_A",
        "outputId": "44a3164b-1682-4560-bb97-e2d1ff2de552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note: Different datatypes can be confusing to begin with. But think of it like this, the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value. And with a lower amount of storage, this generally results in faster computation and a smaller overall model. Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts. For more on this, I'd read up about [precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science))."
      ],
      "metadata": {
        "id": "R5iMgt_R6rJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC1_Fljo3bCJ",
        "outputId": "efd0d75b-b6fb-4ff2-8dd1-b562e05eb692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.cuda>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.dense_dim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jWlLd9-3bFE",
        "outputId": "f084864b-1cc8-4349-999e-10e80f90e869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.dense_dim>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping, stacking, squeezing and unsqueezing"
      ],
      "metadata": {
        "id": "n6WAPi-f9DAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape\n",
        "# note the dot after the no specifies the system that it is floating point"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Cw0plp3bJ0",
        "outputId": "7b0e931b-0a89-43bb-aa2a-08fe030edaab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now let's add an extra dimension with torch.reshape()."
      ],
      "metadata": {
        "id": "VTcm5bkd911d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(2, 7)\n",
        "x_reshaped, x_reshaped.shape\n",
        "\n",
        "# note this: The error message RuntimeError: shape '[2, 7]' is invalid for input of size 7 indicates that you are trying to reshape a tensor with 7 elements into a shape that requires 2 * 7 = 14 elements. The number of elements in the original tensor (7) does not match the number of elements required by the target shape (14).\n",
        "\n",
        "# Looking at the global variables, the tensor x has a shape of [7], meaning it has 7 elements. You are attempting to reshape it into a tensor of shape [2, 7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "1QqUvCwS3bNA",
        "outputId": "1245a01c-1391-47f4-a4be-7def206936a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[2, 7]' is invalid for input of size 7",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-58-1154294592.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add an extra dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 7]' is invalid for input of size 7"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.arange(1.,9.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHqjfbfg3bRu",
        "outputId": "eb56bed0-0a94-45e2-de61-741a931f8de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8.]), torch.Size([8]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: here i created a tensor of size i.e\n",
        "elements 8 and i reshaped it into 2 ,4 and this time it worked because the no of elements requires in the 2,4 is 2*4 = 8 and there are 8 elements in the og tensor \"x\""
      ],
      "metadata": {
        "id": "cVl0NF36_HYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = x.reshape(2,4)\n",
        "x2, x2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQA2N4VK-xhH",
        "outputId": "06a50f86-5e9d-403c-d809-deea7d760914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4.],\n",
              "         [5., 6., 7., 8.]]),\n",
              " torch.Size([2, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x2.view(1, 8)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qupSAHuu-xj_",
        "outputId": "09d9ffce-6b8b-4035-d971-2ad9b165f130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8.]]), torch.Size([1, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember changing the view of the tensor with torch.view() creates a new view of the same tensor (the new  shares the memory with the original tensor).\n",
        "\n",
        "z[ : , 0] selects all rows (:) and the first column (0) of the tensor.\n",
        "\n",
        "\n",
        "z[ : , 0] = 5 assigns the value 5 to every element in that selected column."
      ],
      "metadata": {
        "id": "GNooEsdBBFAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing z changes x\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nirssPT-xmu",
        "outputId": "880e1bd7-a860-40ed-ce26-697d32103bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8.]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHU7-H9G-xpI",
        "outputId": "85623c90-8c1e-4dcc-ea37-8c69c389a028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we change dim to dim=1, the tensors will be stacked along the column, which means they will be transposed and stacked along the column. This will result in a different shape of the output tensor, where the new dimension is inserted at position 1.\n",
        "\n",
        "\n",
        "\n",
        "the dimension varies from [ -2 , 1 ] and -2 = 0 and -1 = 1"
      ],
      "metadata": {
        "id": "pQ6I5OUmECHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try changing dim to dim=1 and see what happens\n",
        "x_stacked = torch.stack([x, x, x, x], dim= -2)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yav73kZLB5bc",
        "outputId": "ad43536f-8fbd-46b9-e3f4-c4cd29d06867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# How about removing all single dimensions from a tensor?\n",
        "\n",
        "To do so you can use torch.squeeze() (I remember this as squeezing the tensor to only have dimensions over 1)."
      ],
      "metadata": {
        "id": "YjqC_LugErkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {x_stacked}\")\n",
        "print(f\"Previous shape: {x_stacked.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_stacked.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M69d4jbbB5eB",
        "outputId": "9c5b9db0-a6bf-41ab-cc29-6d938720ed7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8.],\n",
            "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
            "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
            "        [5., 2., 3., 4., 5., 6., 7., 8.]])\n",
            "Previous shape: torch.Size([4, 8])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8.],\n",
            "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
            "        [5., 2., 3., 4., 5., 6., 7., 8.],\n",
            "        [5., 2., 3., 4., 5., 6., 7., 8.]])\n",
            "New shape: torch.Size([4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "And to do the reverse of torch.squeeze() you can use torch.unsqueeze() to add a dimension value of 1 at a specific index."
      ],
      "metadata": {
        "id": "rdNnN4CrF2Hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iMiEgPJhPIxA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwRLBOcjB5gx",
        "outputId": "579eb969-1030-4eda-e98b-2a1586126065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4174],\n",
              "         [0.9095],\n",
              "         [0.6827]],\n",
              "\n",
              "        [[0.8275],\n",
              "         [0.6723],\n",
              "         [0.9831]]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.rand(1 ,2, 3)\n",
        "y2 = torch.permute(y,(1,2,0))# this will convert the 0->1 , 1->2 , 2->0 (this are dimensions read like this at the o th dimension we place the 1st dimn )\n",
        "print(f\"this is original tensor: {y}\")\n",
        "print(f\"this is permuted tensor: {y2}\")\n",
        "print(f\"this is original shape: {y.shape}\")\n",
        "print(f\"this is permuted shape: {y2.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXBHmf9BPKFc",
        "outputId": "83c94e58-0577-4775-de9f-435152564500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is original tensor: tensor([[[0.6255, 0.4127, 0.6934],\n",
            "         [0.2493, 0.8843, 0.8894]]])\n",
            "this is permuted tensor: tensor([[[0.6255],\n",
            "         [0.4127],\n",
            "         [0.6934]],\n",
            "\n",
            "        [[0.2493],\n",
            "         [0.8843],\n",
            "         [0.8894]]])\n",
            "this is original shape: torch.Size([1, 2, 3])\n",
            "this is permuted shape: torch.Size([2, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INDEXING"
      ],
      "metadata": {
        "id": "BldO7xVyTb3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_Vk2951fULD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1,10).reshape(1, 3, 3)# .ararnge will give 9 eleme and .reshape 1*3*3 =9\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RKKh3TYB5jb",
        "outputId": "9ca2261f-4266-4b32-83e7-83a85f1b817e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets index our new tensor\n",
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY6izqitB5mN",
        "outputId": "7a6d29b2-8bdf-43a5-cdfc-44873d024491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets index the on the middle bracket (dim=1)\n",
        "x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcAB2yEwB5vd",
        "outputId": "23537a0a-d51a-4c8e-e10a-da315272c6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets index the on theinner bracket (last dimn)\n",
        "x[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfukwj70B5yV",
        "outputId": "790138a7-f28e-4d3d-cc3c-798af34497d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also write like this instead of [][]\n",
        "x[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOqiMvrNU2HZ",
        "outputId": "01eeedc1-2c4d-484c-fbe9-d47e1c8775bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "x[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZn7ZWV1U2KK",
        "outputId": "ac1c6398-415a-415e-9d5a-2dfc374cf15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYjCSzNZU2NG",
        "outputId": "c12c35ce-a443-4247-b2ee-ec545fcc2297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtpK4QCkU2Pt",
        "outputId": "f263fde5-e400-455f-90cd-c98ff803c163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :] # same as x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrVZDESVU2Sr",
        "outputId": "f4436224-0fbe-4cf8-9472-6f99958f1b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#index on x to return 9\n",
        "x[0][2][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w12yF8xXJpo",
        "outputId": "44f12415-b655-45a8-bcc2-ea7273cfa635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index on x to return 3,6,9\n",
        "x[ :, :,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exKscSZPXJuE",
        "outputId": "698a0cb0-e6e3-4649-d7ba-744f52c03626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3, 6, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch tensors & NumPy\n",
        "\n",
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "\n",
        "torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.\n",
        "torch.Tensor.numpy() - PyTorch tensor -> NumPy array.\n",
        "Let's try them out.\n"
      ],
      "metadata": {
        "id": "WAmOnIm-WIL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uUJmyvgRU2VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWT3rcJ9Wa6N",
        "outputId": "35f531cd-cc11-433d-e522-242dfeaf16cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1jPhZDEWa9D",
        "outputId": "c9fd6ad0-220a-436a-a032-04195fcd9aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note when converting the np array to tensor to convert we have to use .type()\n",
        "tensor = torch.from_numpy(array).type(torch.float32)\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzYUux-CWa_0",
        "outputId": "6bd81fa9-7807-4c88-d6b7-5d3b90d68c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.from_numpy(array,\n",
        "                          dtype = float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "N9Ej_YLQWbCt",
        "outputId": "fe91f43f-17a4-484e-9a4f-1b29d35fa133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'float32' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-118-2113662969.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tensor = torch.from_numpy(array,\n\u001b[0;32m----> 2\u001b[0;31m                           dtype = float32)\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'float32' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And if you want to go from PyTorch tensor to NumPy array, you can call tensor.numpy()"
      ],
      "metadata": {
        "id": "miXXvsK2Zhgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjZZy_3KWbHx",
        "outputId": "08f5d902-2948-488f-c9e5-5c8f23e134a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hHrXP1UWbK3",
        "outputId": "ebc95631-7285-4353-cbee-a06855a74967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "And the same rule applies as above, if you change the original tensor, the new numpy_tensor stays the same."
      ],
      "metadata": {
        "id": "jkU9qSRsaGEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the tensor, keep the array the same\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQBf8EfdZx0V",
        "outputId": "aebfc9ea-e457-4a5d-dfc8-4016ece8cf71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reproducibility (trying to take the random out of random)\n",
        "\n",
        "\n",
        "As you learn more about neural networks and machine learning, you'll start to discover how much randomness plays a part.\n",
        "\n",
        "Well, pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
        "\n",
        "How does this relate to neural networks and deep learning then?\n",
        "\n",
        "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
        "\n",
        "In short:\n",
        "\n",
        "start with random numbers -> tensor operations -> try to make better (again and again and again)\n",
        "\n",
        "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
        "\n",
        "Why?\n",
        "\n",
        "So you can perform repeatable experiments.\n",
        "\n",
        "For example, you create an algorithm capable of achieving X performance.\n",
        "\n",
        "And then your friend tries it out to verify you're not crazy.\n",
        "\n",
        "How could they do such a thing?\n",
        "\n",
        "That's where reproducibility comes in.\n",
        "\n",
        "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
        "\n",
        "Let's see a brief example of reproducibility in PyTorch.\n",
        "\n",
        "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?"
      ],
      "metadata": {
        "id": "xnYCPrrFcAYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "random_tensor_A == random_tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGAyjcr_WbOS",
        "outputId": "99bdf2ef-f47a-41b2-8904-43ada8235784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.8539, 0.9268, 0.4546, 0.1180],\n",
            "        [0.5832, 0.6901, 0.3991, 0.6317],\n",
            "        [0.6297, 0.2111, 0.9767, 0.2704]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.6556, 0.0944, 0.8068, 0.6754],\n",
            "        [0.1752, 0.2117, 0.8580, 0.6502],\n",
            "        [0.2474, 0.1956, 0.8956, 0.1637]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as you might've expected, the tensors come out with different values.\n",
        "\n",
        "But what if you wanted to create two random tensors with the same values.\n",
        "\n",
        "As in, the tensors would still contain random values but they would be of the same flavour.\n",
        "\n",
        "That's where torch.manual_seed(seed) comes in, where seed is an integer (like 42 but it could be anything) that flavours the randomness.\n",
        "\n",
        "Let's try it out by creating some more flavoured random tensors."
      ],
      "metadata": {
        "id": "QTUEHkWXcNuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# # Set the random seed\n",
        "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called\n",
        "# Without this, tensor_D would be different to tensor_C\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "random_tensor_C == random_tensor_D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pQ67gD-cJa_",
        "outputId": "d65d142a-60e3-4a75-821b-9e41a564efa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Nice!\n",
        "\n",
        "It looks like setting the seed worked.\n",
        "\n",
        "Resource: What we've just covered only scratches the surface of reproducibility in PyTorch. For more, on reproducibility in general and random seeds, I'd checkout:\n",
        "\n",
        "[The PyTorch reproducibility documentation](https://docs.pytorch.org/docs/stable/notes/randomness.html) (a good exercise would be to read through this for 10-minutes and even if you don't understand it now, being aware of it is important).\n",
        "The [Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed)` (this'll give a good overview of random seeds and pseudorandomness in general)."
      ],
      "metadata": {
        "id": "lb8aiD_pcg_v"
      }
    }
  ]
}